{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import compress\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_json(path_to_model):\n",
    "    with open(path_to_model, \"r\") as input_file:\n",
    "        prob_json = json.load(input_file)\n",
    "    return prob_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently, deprecated\n",
    "def write_json_model(prob_json, path_to_model, json_encoder = NpEncoder):\n",
    "    with open(path_to_model, \"w\") as output_file:\n",
    "        json.dump(prob_json, output_file, cls = json_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function identifying conflicting constraints for the interim infeasibile solution, determining if the conflicting constraint is a hard constraint, iterating over the variables in the hard constraints and extract GPI from the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflicting_gpi(prob):\n",
    "    cols = ['gpi', 'ndc', 'client', 'client2', 'breakout', 'measurement', 'region', 'chain', 'subchain']\n",
    "    suspect_gpi_df = pd.DataFrame(columns = cols)\n",
    "    for c in prob.constraints.values():\n",
    "        if not c.valid(0):\n",
    "            ##get variables objects from suspect constraints\n",
    "            constr_vars = c.toDict()['coefficients']\n",
    "            ##get variable names\n",
    "            constr_vars_names = [var['name'] for var in constr_vars]\n",
    "\n",
    "            ##check if the constraint is a soft constraint;\n",
    "            ##currently, soft constraints have lambda_ or sv_ variables\n",
    "            ##any constraint that only includes P_ variables is a hard constraint\n",
    "            suspect_constr = [name.startswith(\"P_\") for name in constr_vars_names]\n",
    "            ##if all the variables in the constraint were of types P_;\n",
    "            if all(suspect_constr):\n",
    "                ##extract GPI, NDC, CLIENT, BREAKOUT, MEASUREMENT, REGION, CHAIN from constraint variables\n",
    "                price_vars = [price.replace('NONPREF_OTH', 'NONPREF-OTH').split('_')[1:] for price in constr_vars_names]\n",
    "                suspect_gpi_df = suspect_gpi_df.append(pd.DataFrame(price_vars, columns = cols))\n",
    "    return suspect_gpi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function identifying decision variables that are set out of bounds in the interim feasibile solution, determining if that variable is a price variable and not a \"soft cap variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violating_gpi(prob):\n",
    "    cols = ['gpi', 'ndc', 'client', 'client2', 'breakout', 'measurement', 'region', 'chain', 'subchain']\n",
    "    suspect_gpi_df = pd.DataFrame(columns = cols)\n",
    "    for v in prob.variables():\n",
    "        if not v.valid(0):\n",
    "            ##get violating variable names\n",
    "            ##check if they are price variables and not SV_ or lambda_ types\n",
    "            if v.name.startswith(\"P_\"):\n",
    "                var_row = v.name.replace('NONPREF_OTH', 'NONPREF-OTH').split('_')[1:]\n",
    "                suspect_gpi_df = suspect_gpi_df.append(pd.DataFrame([var_row], columns = cols))\n",
    "    return suspect_gpi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove hard constraints from the problem json model given a list of suspected GPIs. Any hard constraints that has a variable corresponding to one of the suspected GPIs is removed from the problem. At the same time, a dictionary of those constraints and the suspected GPIs is saved for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_gpi_from_constr(prob_json, suspect_gpi_df):\n",
    "    costr_lst = prob_json['constraints'].copy()\n",
    "    gpi_lst = suspect_gpi_df.gpi.unique()\n",
    "    constr_gpi_dict = {gpi: [] for gpi in gpi_lst}\n",
    "    for constr in prob_json['constraints']:\n",
    "        constr_var_lst = [var['name'] for var in constr['coefficients']]\n",
    "        hard_constr = [name.startswith(\"P_\") for name in constr_var_lst]\n",
    "        if all(hard_constr):\n",
    "            for gpi in gpi_lst:\n",
    "                if any(gpi in var for var in constr_var_lst):\n",
    "                    costr_lst.remove(constr)\n",
    "                    constr_gpi_dict[gpi].append(constr)\n",
    "                    break\n",
    "    return costr_lst, constr_gpi_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove variables corresponding to suspected GPIs from the problem definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove problematic GPIs from variables\n",
    "#currently, deprecated\n",
    "def rm_gpi_from_var(prob_json, var_to_rm_lst):\n",
    "    var_lst = prob_json['variables'].copy()\n",
    "    for var in prob_json['variables']:\n",
    "        if var['name'] in var_to_rm_lst:\n",
    "            var_lst.remove(var)\n",
    "    return var_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to remove variables corresponding to suspected GPIs from the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove problematic GPIs from the objective\n",
    "#currently, deprecated\n",
    "def rm_gpi_from_obj(prob_json, var_to_rm_lst):\n",
    "    obj_var_lst = prob_json['objective']['coefficients'].copy()\n",
    "    for var in prob_json['objective']['coefficients']:\n",
    "        if var in var_to_rm_lst:\n",
    "            obj_var_lst.remove(var)\n",
    "    return obj_var_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, an infeasible problem will be subjected to a while loop. In the loop, a list of suspect GPIs is generated for the infeasible problem. All the hard constraints are then removed from the problem, and the problem is solved again. If the reduced problem is optimal, hard constraints that are removed are added back one by one to obtain a minimal list of problematic GPIs. If the reduced problem turned out to be infeasible again, a new list of suspected GPIs is generated. If the loop could not reach optimality or produce new suspected GPIs, an error is shown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important NOTE**: The required json files containing the model are produced by CPMO in the same folder as the .lp files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit multiple clients at once, a list of the clients should be created as below. The json files should be gathered into a single folder with the path submitted as `orig_path_to_model`. The name of the json file follows the convention `<client_code>_total_prob.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each client, an exclusion file will be generated with the name convention `infeasible_exclusion_gpis_<client>.csv`. Once these files are generated they should be put into the Input file folder while running the model. The name does not need to be altered unless the `INFEASIBLE_EXCLUSION_FILE` value is changed from its default in CPMO_parameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_clients = [3266,3502,3782,3876]\n",
    "for client in inf_clients:\n",
    "    orig_path_to_model = '/home/jupyter/inf_jsons/{0}_total_prob.json'.format(client)\n",
    "    cols = ['gpi', 'ndc', 'client', 'client2', 'breakout', 'measurement', 'region', 'chain', 'subchain']\n",
    "    suspect_gpi_df = pd.DataFrame(columns = cols)\n",
    "\n",
    "    #run the lp for first time\n",
    "    var, prob = pulp.LpProblem.from_json(orig_path_to_model)\n",
    "    prob.solve()\n",
    "    print(f\"status: {prob.status}, {pulp.LpStatus[prob.status]}\")\n",
    "    print(f\"objective: {prob.objective.value()}\")\n",
    "    status = pulp.LpStatus[prob.status]\n",
    "    orig_prob_json = read_model_json(orig_path_to_model)\n",
    "    prob_json = orig_prob_json.copy()\n",
    "\n",
    "    while status == \"Infeasible\":\n",
    "        #create initial df of suspect GPIs\n",
    "        new_found_gpi_df = pd.concat([conflicting_gpi(prob), violating_gpi(prob)])\n",
    "        new_found_gpi_df.drop_duplicates(inplace = True, ignore_index = True)\n",
    "        if new_found_gpi_df.empty:\n",
    "            #infeasibility lies in the interaction of different a mix of soft and hard constraints\n",
    "            #this needs further research because something like this should not happen!\n",
    "            #or there are other hard constraints which are not identified in this notebook\n",
    "            print(\"Error!: No more GPIs are suspected but the infeasibility issue persists.\")\n",
    "            break\n",
    "        suspect_gpi_df = suspect_gpi_df.append(new_found_gpi_df)\n",
    "\n",
    "        print(f\"unique number of new suspect GPIs found: {len(new_found_gpi_df.gpi.unique())}\")\n",
    "        suspect_gpi_master_lst = list(suspect_gpi_df.gpi.unique())\n",
    "\n",
    "        print(f\"Identifying hard constraints to be removed from the original problem...\")    \n",
    "        constr_lst, constr_gpi_dict = rm_gpi_from_constr(prob_json,\n",
    "                                                         suspect_gpi_df.loc[suspect_gpi_df.gpi.isin(suspect_gpi_master_lst), ])\n",
    "\n",
    "        print(f\"Solving the reduced problem...\")\n",
    "        prob_json['constraints'] = constr_lst\n",
    "        var, prob = pulp.LpProblem.from_dict(prob_json)\n",
    "        prob.solve()\n",
    "        print(f\"status: {prob.status}, {pulp.LpStatus[prob.status]}\")\n",
    "        print(f\"objective: {prob.objective.value()}\")\n",
    "        status = pulp.LpStatus[prob.status]\n",
    "\n",
    "        if pulp.LpStatus[prob.status] == \"Optimal\":\n",
    "            safe_gpi = []\n",
    "            unsafe_gpi = []\n",
    "            print(\"Add back hard constraint corresponding to suspect GPIs one by one...\")\n",
    "            for gpi in suspect_gpi_master_lst:\n",
    "                constr_lst.extend(constr_gpi_dict[gpi])\n",
    "                prob_json['constraints'] = constr_lst\n",
    "                new_var, new_prob = pulp.LpProblem.from_dict(prob_json)\n",
    "                new_prob.solve()\n",
    "                if pulp.LpStatus[new_prob.status] == \"Optimal\":\n",
    "                    safe_gpi.append(gpi)\n",
    "                    print(f\"{gpi} from the suspected list is safe\")\n",
    "                else:\n",
    "                    unsafe_gpi.append(gpi)\n",
    "                    print(f\"{gpi} from the suspected list is unsafe\")\n",
    "                    for constr in constr_gpi_dict[gpi]:\n",
    "                        constr_lst.remove(constr)\n",
    "            print(f\"List of unsafe GPIs: {unsafe_gpi}\")\n",
    "\n",
    "    #Write problem gpis to exclusion file\n",
    "    region = 'ALL'\n",
    "    gpi_exclusion = pd.DataFrame(columns = ['CLIENT', 'REGION', 'GPI'])\n",
    "    gpi_exclusion['GPI'] = unsafe_gpi\n",
    "    gpi_exclusion['CLIENT'] = client\n",
    "    gpi_exclusion['REGION'] = region\n",
    "    gpi_exclusion.to_csv('/home/jupyter/infeasible_exclusions/infeasible_exclusion_gpis_{0}.csv'.format(client), index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
